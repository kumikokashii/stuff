STATS NOTES:

===========================================
Binomial Distribution
===========================================
* n independent observations

* Each observation is Bernoulli Distribution
  * 'success' (1) or 'failure' (0)
  * Probability of success is p
  * Mean = (p * 1) + ((1 - p) * 0) = p
  * Variance = p(1 - p)

* Written B(n, p)
* Mean = np
* Variance = np(1 - p)

* Sampling distribution
  * First sampling (picking random n from population) gives the value of B_1(n, p)
  * Then the proportion of 'success' is B_1(n, p) / n
  * Continue sampling...
  
  * Then sampling distribution (distribution of the proportion of 'success' from various samples) has:
    * Mean = p
    * Variance = p(1 - p) / n
    * Rule of thumb: If np >= 10 and n(1 - p) >= 10, then normal distribution

===========================================
Central Limit Theorem
===========================================
* Sampling distributin of sample mean (where sample size n is large enough, like 30) 
is a normal distribution with:
  * Mean = population mean
  * Variance = population variance * (1 / n)
* Populatin distribution can be of any shape (not normal distribution)
  
* Example: https://www.methodsconsultants.com/tutorial/the-central-limit-theorem-and-its-implications-for-statistical-inference/

===========================================
Hypothesis Testing
===========================================
1. Your sample has a value of x with hypothesis A
2. Assume the null hypothesis is true (hypothesis A is not true)
3. Given your sample size n, population mean, and population standard deviation, 
find the probability of x happening: p-value (probability value)
4. Assumption is that the possibility of x happening is larger than the (given) significance level
5. If p-value < significance level, a contradiction. Reject the null hypothesis. Hypothesis A is true.

* The significance level is usually 5% or less
* If sample size is small (like less than 30), use t-score rather than z-socre

===========================================
Confidence Level and Interval (Margin or Error)
===========================================
* Example: 'With 95% confidence level, x is between 5 and 10 (sample size 100)' means that 
when this experiment is repeated with different sets of samples (of the same smaple size 100), 
95% of the times the intervals (that are different every time) will contain true x.

1. Pick n samples from population (ofen, we want to guess population mean)
2. We find that sample mean is p (chance of the 'success' event happening is (p * 100)%)
3. Sampling distribution is a normal distribution with its mean being population mean and
its standarard deviation being population standard deviation * (1 / n) ^ (1 / 2) = sampling_sd
4. There's a 95% chance that p is within 2 sampling_sd of population mean
i.e. there's a 95% chance that population mean is within 2 sampling_sd of p
6. We don't know population standard deviation to calculate sampling_sd
7. Instead estimate with sample standard deviation: 
Standard Error = sample standard deviation * (1 / n) ^ (1 / 2) = se
8. We're 95% confident that the interval (p - 2*se, p + 2*se) captured population mean

* Use t-score (degree of freedom = n - 1) instead of z-score

* Samples need to be randomly picked
* Need n >= 30, or samples are picked from (or resemble) normal distribution (Normal Condition)
* Sample size needs to be less than 10% of population size (Independence Condition)

===========================================
Comparing two samples, difference between the two populations
===========================================
* Population A: pop_mean_A, pop_var_A
* Population B: pop_mean_B, pop_var_B
* Sample A (size n) from population A: sample_mean_A, sample_var_A
* Sample B (size m) from population B: sample_mean_B, sample_var_B

* Sampling distribution of sample_mean_A: sd_mean_A = pop_mean_A, sd_var_A = pop_var_A / n
* Sampling distribution of sample_mean_B: sd_mean_B = pop_mean_B, sd_var_B = pop_var_B / m

* Sampling distribution of sample_mean_A - sample_mean_B:
  mean = sd_mean_A - sd_mean_B = pop_mean_A - pop_mean_B
  var = sd_var_A + sd_var_B = (pop_var_A / n) + (pop_var_B / m)

* AB Testing: Assume the null hypothes (pop_mean_A - pop_mean_B = 0)
* Estimate pop_var_A with sample_var_A, pop_var_B with sample_var_B (use t-score instead of z-score)
* https://conductrics.com/pvalues

===========================================
Sample size for AB testing
===========================================
* alpha i.e. type 1 error i.e. significance level (i.e. false positive rate) often 5%
  = P(positive hypothesis | negative results)
  
  false positive (i.e. false alarm)
  = null hypothesis is rejected, but null hypothesis is true

  reliability (i.e. confidence level i.e. specificity)
  = 1 - alpha
  = P(negative hypothesis | negative results)
  = true negative rate
  = Set an assumption that (reliability * 100)% of the times, null hypothesis is true
    i.e. there's a sample mean s.t. beyond this sample mean, null hypothesis is no longer true
  
* beta i.e. type 2 error (i.e. falset negative rate)
  = P(negative hypothesis | positive results)

  false negative (i.e. failure to detect)
  = null hypothesis is accepted, but null hypothesis is not true

  power (i.e. sensitivity) often 80%
  = 1 - beta
  = P(positive hypothesis | positive results)
  = true positive rate
  = chance to reject null hypothesis correctly
    i.e. if the test is repeated, (power * 100)% of times, effect will be flagged as statistically significant
        
* Let n be unknown sample size, sig be significance level, power be power
  Let group A be an alternative group with: mean_A, var_A = mean_A(1 - mean_A) / n
  Let group B be a population group with: mean_B, var_B = mean_B(1 - mean_B) / n
  Find n
  
  Null hypothesis (Assume no difference b/w group A and group B):
    Let A_null(x) denote area under null hypothesis sample distribution curve up to x
    null_mean = mean_A - mean_B = 0
    null_var = var_A + var_B
    Let x_rel be sample mean value s.t. A_null(x_rel) = reliability = 1 - sig
    
  Hypothesis A (Assume there's difference b/w group A and group B):
    Let A_diff(x) denote area under hypothesis A's sample distribution curve up to x
    diff_mean = mean_A - mean_B
    diff_var = var_A + var_B
    Let x_power be sample mean value s.t. 1 - A_diff(x_power) = power
    
  We are given x_rel = x_power by definition of the test
  
  Look at Hypothesis A's sampling distribution
    Let z_power be z-score of x_power
    z_power = (diff_mean - x_power) / (diff_var) ** (1 / 2)
            = (diff_mean - x_rel) / (diff_var) ** (1 / 2)
            = [diff_mean / (diff_var) ** (1 / 2)] - [x_rel / (diff_var) ** (1 / 2)]  # 1
                 
  Look at null hypothesis's sampling distribution
    Let z_rel be z-score of x_rel
    z_rel = (x_rel - null_mean) / (null_var) ** (1 / 2)
          = (x_rel - 0) / (diff_var) ** (1 / 2)
          = x_rel / (diff_var) ** (1 / 2)  # 2
               
  From #1, 2,
    z_power = [diff_mean / (diff_var) ** (1 / 2)] - z_rel
            = [(mean_A - mean_B) / (var_A + var_B) ** (1 / 2)] - z_rel
            = {(mean_A - mean_B) / [(mean_A(1 - mean_A) + mean_B(1 - mean_B)) / n] ** (1 / 2)} - z_rel
    
    Solve for n
    
    (mean_A - mean_B) / [(mean_A(1 - mean_A) + mean_B(1 - mean_B)) / n] ** (1 / 2) = z_power + z_rel
    [n / (mean_A(1 - mean_A) + mean_B(1 - mean_B))] ** (1 / 2) = (z_power + z_rel) / (mean_A - mean_B)
    n / [mean_A(1 - mean_A) + mean_B(1 - mean_B)] = [(z_power + z_rel) / (mean_A - mean_B)] ** 2
    n = [mean_A(1 - mean_A) + mean_B(1 - mean_B)] * [(z_power + z_rel) / (mean_A - mean_B)] ** 2
    
* Rough estimate of n with 5% significance level and 80% power:
  1. Let var = var_A = var_B
  2. z_rel = 1.644854
  3. z_power = 0.841621
  5. Let change_wanted = mean_A - mean_B
  6. n = [mean_A(1 - mean_A) + mean_B(1 - mean_B)] * [(z_power + z_rel) / (mean_A - mean_B)] ** 2
       = (var + var) * [(1.644854 + 0.841621) / change_wanted] ** 2
       = (2 * var) * (2.486475) ** 2 / change_wanted ** 2
       = 12.36511585125 * var / change_wanted ** 2
  
* 0.8 MDE (Minimal Detectable Effect): Given sample size and sample variance, the smallest effect size detectable at 80% power.

